import streamlit as st
import pandas as pd
import numpy as np
import datetime as dt
import plotly.graph_objects as go
from prophet import Prophet
import yfinance as yf
import ta
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
import shap
import matplotlib.pyplot as plt
import logging
import atexit
import shutil
from pmdarima import auto_arima

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(filename='error_log.txt', level=logging.INFO)

# æ¸…ç† cmdstanpy è‡¨æ™‚æª”æ¡ˆ
def cleanup_cmdstanpy_tmpdir():
    try:
        shutil.rmtree(Prophet()._tmpdir, ignore_errors=True)
    except Exception as e:
        logging.error(f"æ¸…ç† cmdstanpy è‡¨æ™‚æª”æ¡ˆå¤±æ•—: {e}")

atexit.register(cleanup_cmdstanpy_tmpdir)

# Streamlit é é¢é…ç½®
st.set_page_config(page_title="æ™ºèƒ½é¸è‚¡å¹³å° PRO (ç¾è‚¡ç‰ˆ)", layout="wide", initial_sidebar_state="expanded")

# ä½¿ç”¨èªªæ˜
st.sidebar.title("ğŸ“˜ ä½¿ç”¨èªªæ˜")
show_tech_help = st.sidebar.checkbox("ğŸ“Š é¡¯ç¤ºæŠ€è¡“æŒ‡æ¨™èªªæ˜", value=False)
if show_tech_help:
    st.sidebar.markdown("""
    #### ğŸŸ¢ æŠ€è¡“æŒ‡æ¨™èªªæ˜ (ç¾è‚¡å„ªåŒ–ç‰ˆ)
    
    **åˆéšæŒ‡æ¨™å‡ç´šï¼š**
    - ğŸ“ˆ **æ™ºèƒ½RSI 2.0**ï¼šç§‘æŠ€è‚¡<25/å…¶ä»–<30ç‚ºè¶…è³£ï¼Œ>75/>70ç‚ºè¶…è²·ï¼Œéœ€ATRç¢ºèª
    - ğŸ“‰ **MACD 2.0**ï¼šé»ƒé‡‘äº¤å‰éœ€é€£çºŒå…©æ—¥åƒ¹æ ¼+ATRç¢ºèª
    - ğŸšï¸ **å¸ƒæ—é€šé“PRO**ï¼šçªç ´éœ€>1.5å€ATRï¼ŒçµåˆVWAP
    - ğŸ’¹ **æˆäº¤é‡é€²éš**ï¼šç§‘æŠ€è‚¡éœ€2.5å€å‡é‡/å…¶ä»–2å€ï¼Œé…åˆOBV
    
    **é«˜éšæŒ‡æ¨™æ–°å¢ï¼š**
    - ğŸ“ **VWAP**ï¼šæˆäº¤é‡åŠ æ¬Šå¹³å‡åƒ¹ï¼Œåƒ¹æ ¼>VWAPç‚ºå¤šé ­ä¿¡è™Ÿ
    - ğŸŒªï¸ **ATRéæ¿¾**ï¼šç¢ºä¿çªç ´ä¿¡è™ŸçœŸå¯¦ï¼Œ>1.5å€ATRæ‰è§¸ç™¼
    - ğŸŒ€ **TD9çµæ§‹+**ï¼šå®Œæˆå¾Œéœ€æˆäº¤é‡+ATRé…åˆ
    - ğŸ”„ **RSIèƒŒé›¢2.0**ï¼šåƒ¹æ ¼æ³¢å‹•>5%ä¸”ATRç¢ºèª
    
    **é æ¸¬æ¨¡å‹å‡ç´šï¼š**
    - â³ **Prophet 30å¤©é æ¸¬**ï¼šè—è‰²ç·šç‚ºå¯¦éš›åƒ¹æ ¼ï¼Œç¶ è‰²ç·šç‚ºé æ¸¬åƒ¹æ ¼ï¼Œæ·ºè—è‰²ç‚ºç½®ä¿¡å€é–“ï¼Œç´å…¥ç´æ–¯é”å…‹100æŒ‡æ•¸
    - ğŸš€ **XGBoost/éš¨æ©Ÿæ£®æ—/LightGBMé€²éš**ï¼šèª¿å„ªåƒæ•¸ï¼Œæ–°å¢52é€±é«˜ä½é»èˆ‡ç´æ–¯é”å…‹ç›¸é—œæ€§ï¼Œç‰¹å¾µé‡è¦æ€§å¯é¸é¡¯ç¤º
    - ğŸ“‰ **ARIMA**ï¼šæä¾›ç·šæ€§æ™‚é–“åºåˆ—é æ¸¬ï¼Œè£œå…… Prophet çš„é•·æœŸè¶¨å‹¢åˆ†æ
    
    **ç¾è‚¡å°ˆå±¬ï¼š**
    - ğŸ·ï¸ **è¡Œæ¥­è‡ªé©æ‡‰**ï¼šç§‘æŠ€è‚¡æ›´å¯¬é¬†é–¾å€¼
    - âš–ï¸ **å¤šç©ºæ¬Šé‡**ï¼šå¤šé ­å¸‚å ´ä¿¡è™Ÿæ”¾å¤§1.2x
    - ğŸ“ **é»ƒé‡‘æ¯”ç‡å›èª¿**ï¼šé—œéµæ”¯æŒé˜»åŠ›ä½
    - ğŸ–¼ï¸ **åœ–å½¢å½¢æ…‹**ï¼šé ­è‚©é ‚/åº•ã€é›™é ‚/åº•ï¼Œ10å¤©å…§æœ‰æ•ˆ
    """)

# è‚¡ç¥¨åˆ†é¡ï¼ˆåŒ…å«ä¸­æ–‡åç¨±ï¼‰
stock_categories = {
    "ç†±é–€è‚¡": [
        ("TSLA", "ç‰¹æ–¯æ‹‰"), ("NVDA", "è‹±å‰é”"), ("TQQQ", "ä¸‰å€åšå¤šç´æŒ‡ETF"),
        ("SQQQ", "ä¸‰å€åšç©ºç´æŒ‡ETF"), ("TEM", "Tempus AI"), ("AAPL", "è˜‹æœ"),
        ("TLT", "20å¹´æœŸåœ‹å‚µETF")
    ],
    "MAG7": [
        ("AAPL", "è˜‹æœ"), ("MSFT", "å¾®è»Ÿ"), ("GOOG", "è°·æ­Œ"), ("AMZN", "äºé¦¬éœ"),
        ("META", "Meta"), ("NVDA", "è‹±å‰é”"), ("TSLA", "ç‰¹æ–¯æ‹‰")
    ],
    "AI è‚¡": [
        ("NVDA", "è‹±å‰é”"), ("AMD", "è¶…å¾®"), ("TSM", "å°ç©é›»"), ("PLTR", "Palantir"),
        ("SMCI", "è¶…å¾®é›»è…¦"), ("ASML", "é˜¿æ–¯éº¥"), ("TEM", "Tempus AI"), ("INTC", "è‹±ç‰¹çˆ¾"),
        ("SNOW", "Snowflake")
    ],
    "ETF": [
        ("SPY", "æ¨™æ™®500 ETF"), ("QQQ", "ç´æ–¯é”å…‹100 ETF"), ("TQQQ", "ä¸‰å€åšå¤šç´æŒ‡ETF"),
        ("SQQQ", "ä¸‰å€åšç©ºç´æŒ‡ETF"), ("ARKK", "æ–¹èˆŸå‰µæ–°ETF"), ("VOO", "å…ˆé‹’æ¨™æ™®500 ETF"),
        ("IWF", "ç¾…ç´ 1000æˆé•·ETF")
    ],
    "é»ƒé‡‘ / å‚µåˆ¸ / é‡‘è": [
        ("GLD", "é»ƒé‡‘ETF"), ("TLT", "20å¹´æœŸåœ‹å‚µETF"), ("XLF", "é‡‘èæ¿å¡ŠETF"),
        ("JPM", "æ‘©æ ¹å¤§é€š"), ("BAC", "ç¾åœ‹éŠ€è¡Œ"), ("SLV", "ç™½éŠ€ETF"), ("GS", "é«˜ç››")
    ],
    "æ¯”ç‰¹å¹£ / å€å¡Šéˆ": [
        ("BITO", "æ¯”ç‰¹å¹£æœŸè²¨ETF"), ("MARA", "é¦¬æ‹‰æ¾æ•¸ä½"), ("RIOT", "Riot Platforms"),
        ("COIN", "Coinbase"), ("GBTC", "ç°åº¦æ¯”ç‰¹å¹£ä¿¡è¨—"), ("ETHE", "ç°åº¦ä»¥å¤ªåŠä¿¡è¨—")
    ],
    "èƒ½æº / çŸ³æ²¹": [
        ("XLE", "èƒ½æºæ¿å¡ŠETF"), ("CVX", "é›ªä½›é¾"), ("XOM", "åŸƒå…‹æ£®ç¾å­š"),
        ("OXY", "è¥¿æ–¹çŸ³æ²¹"), ("BP", "è‹±åœ‹çŸ³æ²¹"), ("SLB", "æ–¯å€«è²è¬")
    ],
    "5G / åŠå°é«”": [
        ("QCOM", "é«˜é€š"), ("AVGO", "åšé€š"), ("SWKS", "æ€ä½³è¨Š"), ("NXPI", "æ©æ™ºæµ¦"),
        ("MRVL", "é‚å¨çˆ¾ç§‘æŠ€"), ("AMD", "è¶…å¾®")
    ],
    "æ–°èƒ½æº / é›»å‹•è»Š": [
        ("LI", "ç†æƒ³æ±½è»Š"), ("NIO", "è”šä¾†"), ("LCID", "Lucid"), ("RIVN", "Rivian"),
        ("FSLR", "ç¬¬ä¸€å¤ªé™½èƒ½")
    ],
    "é†«ç™‚ / ç”Ÿç‰©ç§‘æŠ€": [
        ("PFE", "è¼ç‘"), ("MRNA", "Moderna"), ("GILD", "å‰åˆ©å¾·ç§‘å­¸"), ("BIIB", "ç™¾å¥")
    ],
    "çœ‹æ·¡æ§“æ¡¿ ETF": [
        ("NVDQ", "2å€åšç©ºè‹±å‰é”ETF"), ("NVD", "1.5å€åšç©ºè‹±å‰é”ETF"), ("NVD3", "3å€åšç©ºè‹±å‰é”ETF"),
        ("TSLS", "åšç©ºç‰¹æ–¯æ‹‰ETF"), ("TSLZ", "2å€åšç©ºç‰¹æ–¯æ‹‰ETF"), ("TSLQ", "1.5å€åšç©ºç‰¹æ–¯æ‹‰ETF"),
        ("3STP", "3å€åšç©ºæ¨™æ™®ç§‘æŠ€ETF")
    ]
}

# æ•¸æ“šç²å–å‡½æ•¸
def fetch_price_data(symbol, retries=5):
    end_date = dt.date.today()
    start_date = end_date - dt.timedelta(days=365)
    
    for attempt in range(retries):
        try:
            ticker = yf.Ticker(symbol)
            df = ticker.history(start=start_date, end=end_date + dt.timedelta(days=1), interval="1d")
            fetch_time = dt.datetime.now()
            
            if df.empty or df["Close"].isna().all():
                raise ValueError(f"yfinance: ç„¡æœ‰æ•ˆæ•¸æ“š for {symbol}")
            
            df = df.reset_index().rename(columns={
                "Date": "date",
                "Close": "close",
                "Volume": "volume",
                "High": "high",
                "Low": "low"
            })
            df["date"] = df["date"].dt.tz_localize(None)
            df = df[["date", "close", "volume", "high", "low"]]
            df = df.dropna()  # ç§»é™¤ç„¡æ•ˆæ•¸æ“š
            
            logging.info(f"yfinance: æ•¸æ“šç²å–æˆåŠŸ for {symbol} at {fetch_time}, latest date: {df['date'].max()}")
            return df, fetch_time, "yfinance"
        except Exception as e:
            logging.error(f"yfinance fetch_price_data({symbol}) å¤±æ•— on attempt {attempt+1}: {e}")
            if attempt == retries - 1:
                st.error(f"ç„¡æ³•ç²å– {symbol} çš„æ•¸æ“šï¼Œè«‹æª¢æŸ¥ç¶²çµ¡æˆ–è‚¡ç¥¨ä»£ç¢¼")
                return None, None, None

def fetch_nasdaq_data():
    df, fetch_time, source = fetch_price_data("QQQ")
    if df is not None:
        df = df.rename(columns={"close": "nasdaq_close", "volume": "nasdaq_volume"})
        return df[["date", "nasdaq_close", "nasdaq_volume"]]
    return None

# æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
def calculate_all_indicators(df, sector=""):
    df = df.copy()
    closes = df["close"].values
    highs = df["high"].values
    lows = df["low"].values
    volumes = df["volume"].values
    
    # ç¢ºä¿ç„¡ NaN æˆ–é›¶å€¼
    df = df.dropna()
    if len(df) < 50:  # ç¢ºä¿è¶³å¤ æ•¸æ“š
        logging.warning(f"æ•¸æ“šä¸è¶³ for {sector}: {len(df)} rows")
        return df, {}, [], []
    
    df["ma5"] = pd.Series(closes).rolling(window=5).mean()
    df["ma20"] = pd.Series(closes).rolling(window=20).mean()
    df["ma50"] = pd.Series(closes).rolling(window=50).mean()
    df["rsi"] = ta.momentum.RSIIndicator(pd.Series(closes)).rsi()
    macd = ta.trend.MACD(pd.Series(closes))
    df["macd"] = macd.macd()
    df["macd_signal"] = macd.macd_signal()
    df["macd_hist"] = macd.macd_diff()
    bb = ta.volatility.BollingerBands(pd.Series(closes))
    df["bb_upper"] = bb.bollinger_hband()
    df["bb_lower"] = bb.bollinger_lband()
    df["bb_break"] = df.apply(
        lambda row: "ä¸Šè»Œ" if row.close > row.bb_upper else ("ä¸‹è»Œ" if row.close < row.bb_lower else "ä¸­é–“"), 
        axis=1
    )
    df["vwap"] = (df["close"] * df["volume"]).cumsum() / df["volume"].cumsum()
    df["vwap_signal"] = df["close"] > df["vwap"]
    df["atr"] = ta.volatility.AverageTrueRange(pd.Series(highs), pd.Series(lows), pd.Series(closes)).average_true_range()
    df["vol_avg20"] = pd.Series(volumes).rolling(window=20).mean()
    vol_threshold = 2.5 if sector in ["Technology", "Consumer Cyclical"] else 2
    df["vol_spike"] = df["volume"] > vol_threshold * df["vol_avg20"]
    df["adx"] = ta.trend.ADXIndicator(pd.Series(highs), pd.Series(lows), pd.Series(closes)).adx()
    df["td9_down"] = (df["close"] < df["close"].shift(4)).astype(int)
    df["td9_count"] = df["td9_down"] * (
        df["td9_down"].groupby((df["td9_down"] != df["td9_down"].shift()).cumsum()).cumcount() + 1
    )
    obv = [0]
    for i in range(1, len(df)):
        if closes[i] > closes[i-1]:
            obv.append(obv[-1] + volumes[i])
        elif closes[i] < closes[i-1]:
            obv.append(obv[-1] - volumes[i])
        else:
            obv.append(obv[-1])
    df["obv"] = obv
    df["obv_ma20"] = pd.Series(obv).rolling(window=20).mean()
    df["52w_high"] = pd.Series(highs).rolling(window=252, min_periods=20).max()
    df["52w_low"] = pd.Series(lows).rolling(window=252, min_periods=20).min()
    
    lookback = 60
    recent_high = pd.Series(highs[-lookback:]).max()
    recent_low = pd.Series(lows[-lookback:]).min()
    diff = recent_high - recent_low
    fib_levels = {
        "0%": recent_high,
        "23.6%": recent_high - diff * 0.236,
        "38.2%": recent_high - diff * 0.382,
        "50%": recent_high - diff * 0.5,
        "61.8%": recent_high - diff * 0.618,
        "100%": recent_low
    }
    
    hs_patterns = []
    dt_patterns = []
    for i in range(2, len(df)-2):
        if (highs[i] > highs[i-1] and highs[i] > highs[i+1] and
            highs[i-1] > highs[i-2] and highs[i+1] > highs[i+2]):
            hs_patterns.append(("é ­è‚©é ‚", df["date"].iloc[i]))
        if (lows[i] < lows[i-1] and lows[i] < lows[i+1] and
            lows[i-1] < lows[i-2] and lows[i+1] < lows[i+2]):
            hs_patterns.append(("é ­è‚©åº•", df["date"].iloc[i]))
    for i in range(1, len(df)-1):
        threshold = 0.05
        if (abs(highs[i] - highs[i-1]) < threshold * highs[i] and
            highs[i] > highs[i-2] and highs[i] > highs[i+1]):
            dt_patterns.append(("é›™é ‚", df["date"].iloc[i]))
        if (abs(lows[i] - lows[i-1]) < threshold * lows[i] and
            lows[i] < lows[i-2] and lows[i] < lows[i+1]):
            dt_patterns.append(("é›™åº•", df["date"].iloc[i]))
    
    return df, fib_levels, hs_patterns, dt_patterns

# ä¿¡è™Ÿç”Ÿæˆ
def enhanced_generate_signal(df, fib_levels, hs_patterns, dt_patterns, sector=""):
    latest = df.iloc[-1]
    prev = df.iloc[-2]
    prev2 = df.iloc[-3] if len(df) > 2 else prev
    score = 0
    explanation = []
    weight = 1.2 if latest["close"] > df["ma50"].iloc[-1] else 0.8
    
    def price_confirmation(condition, periods=2):
        if periods == 2:
            return condition(latest["close"], prev["close"]) and condition(prev["close"], prev2["close"])
        return condition(latest["close"], prev["close"])
    
    rsi_buy_threshold = 25 if sector in ["Technology", "Consumer Cyclical"] else 30
    rsi_sell_threshold = 75 if sector in ["Technology", "Consumer Cyclical"] else 70
    if latest.rsi < rsi_buy_threshold and price_confirmation(lambda x, y: x > y) and (latest["close"] - prev["close"]) > 1.5 * latest["atr"]:
        score += 1.5 * weight
        explanation.append(f"RSIè¶…è³£({latest.rsi:.1f})ï¼Œåƒ¹æ ¼+ATRç¢ºèª")
    elif latest.rsi > rsi_sell_threshold and price_confirmation(lambda x, y: x < y) and (prev["close"] - latest["close"]) > 1.5 * latest["atr"]:
        score -= 1 * weight
        explanation.append(f"RSIè¶…è²·({latest.rsi:.1f})ï¼Œåƒ¹æ ¼+ATRç¢ºèª")
    
    if latest.macd_hist > 0 and prev.macd_hist < 0 and price_confirmation(lambda x, y: x > y) and (latest["close"] - prev["close"]) > 1.5 * latest["atr"]:
        score += 1.2 * weight
        explanation.append(f"MACDæŸ±ç‹€åœ–ç¿»æ­£ï¼Œåƒ¹æ ¼+ATRç¢ºèª")
    elif latest.macd_hist < 0 and prev.macd_hist > 0 and price_confirmation(lambda x, y: x < y):
        score -= 1 * weight
        explanation.append(f"MACDæŸ±ç‹€åœ–ç¿»è² ï¼Œåƒ¹æ ¼ç¢ºèª")
    
    if latest.bb_break == "ä¸‹è»Œ" and (latest["close"] - latest["bb_lower"]) > 1.5 * latest["atr"]:
        score += 1.5 * weight
        explanation.append(f"å¸ƒæ—å¸¶è·Œç ´ä¸‹è»Œï¼ŒATRç¢ºèª")
    elif latest.bb_break == "ä¸Šè»Œ" and (latest["bb_upper"] - latest["close"]) > 1.5 * latest["atr"]:
        score -= 1 * weight
        explanation.append(f"å¸ƒæ—å¸¶çªç ´ä¸Šè»Œï¼ŒATRç¢ºèª")
    
    if latest.vwap_signal and price_confirmation(lambda x, y: x > y):
        score += 1.2 * weight
        explanation.append(f"åƒ¹æ ¼çªç ´VWAP({latest.vwap:.2f})ï¼Œå¤šé ­ä¿¡è™Ÿ")
    elif not latest.vwap_signal and price_confirmation(lambda x, y: x < y):
        score -= 0.8 * weight
        explanation.append(f"åƒ¹æ ¼è·Œç ´VWAP({latest.vwap:.2f})ï¼Œç©ºé ­ä¿¡è™Ÿ")
    
    if latest.vol_spike and latest.close > prev.close:
        score += 1.8 * weight
        explanation.append(f"æ”¾é‡ä¸Šæ¼²ï¼Œæˆäº¤é‡:{latest.volume/1e6:.1f}M")
    
    if latest.adx > 25:
        score += 0.5 * weight if latest["close"] > df["ma50"].iloc[-1] else -0.5 * weight
        explanation.append(f"{'å¼·å‹ä¸Šå‡' if latest['close'] > df['ma50'].iloc[-1] else 'å¼·å‹ä¸‹é™'}è¶¨å‹¢(ADX:{latest.adx:.1f})")
    
    if df["td9_count"].iloc[-1] >= 9 and latest.vol_spike:
        score += 1.5 * weight
        explanation.append(f"TD9çµæ§‹å®Œæˆï¼Œæˆäº¤é‡ç¢ºèª")
    
    if latest.obv > latest.obv_ma20 and latest.close > prev.close:
        score += 0.8 * weight
        explanation.append(f"OBVçªç ´20æ—¥å‡ç·šï¼Œåƒ¹æ ¼ä¸Šå‡")
    
    current_price = latest["close"]
    for level, price in fib_levels.items():
        if abs(current_price - price) < current_price * 0.01:
            if level in ["38.2%", "50%", "61.8%"]:
                score += 1
                explanation.append(f"è§¸åŠé»ƒé‡‘æ¯”ç‡ {level} ({price:.2f})")
    
    if hs_patterns and (df["date"].iloc[-1] - hs_patterns[-1][1]).days < 10:
        last_pattern = hs_patterns[-1]
        score += 1.5 if last_pattern[0] == "é ­è‚©åº•" else -1.5
        explanation.append(f"è¿‘æœŸ{last_pattern[0]} (æ—¥æœŸ: {last_pattern[1].strftime('%Y-%m-%d')})")
    if dt_patterns and (df["date"].iloc[-1] - dt_patterns[-1][1]).days < 10:
        last_pattern = dt_patterns[-1]
        score += 1 if last_pattern[0] == "é›™åº•" else -1
        explanation.append(f"è¿‘æœŸ{last_pattern[0]} (æ—¥æœŸ: {last_pattern[1].strftime('%Y-%m-%d')})")
    
    signal = (
        "ğŸŸ¢ å¼·åŠ›è²·å…¥" if score >= 5 else
        "ğŸŸ¡ è¬¹æ…è²·å…¥" if score >= 3 else
        "ğŸ”´ å¼·åŠ›è³£å‡º" if score <= -3 else
        "ğŸ”´ è€ƒæ…®è³£å‡º" if score <= -1 else
        "âšª ä¸­æ€§è§€æœ›"
    )
    
    return signal, explanation, score, latest

# åœ–è¡¨
def plot_fibonacci_levels(fig, df, fib_levels):
    last_date = df["date"].iloc[-1]
    for level, price in fib_levels.items():
        fig.add_shape(
            type="line", x0=df["date"].iloc[0], y0=price, x1=last_date, y1=price,
            line=dict(color="purple", width=1, dash="dot"), name=f"é»ƒé‡‘æ¯”ç‡ {level}"
        )
        fig.add_annotation(x=last_date, y=price, text=f"é»ƒé‡‘æ¯”ç‡ {level}", showarrow=False, yshift=10)
    return fig

def plot_ichimoku(fig, df):
    high_9 = df["high"].rolling(window=9).max()
    low_9 = df["low"].rolling(window=9).min()
    df["ichi_tenkan"] = (high_9 + low_9) / 2
    high_26 = df["high"].rolling(window=26).max()
    low_26 = df["low"].rolling(window=26).min()
    df["ichi_kijun"] = (high_26 + low_26) / 2
    df["ichi_senkou_a"] = ((df["ichi_tenkan"] + df["ichi_kijun"]) / 2).shift(26)
    high_52 = df["high"].rolling(window=52).max()
    low_52 = df["low"].rolling(window=52).min()
    df["ichi_senkou_b"] = ((high_52 + low_52) / 2).shift(26)
    
    fig.add_trace(go.Scatter(x=df["date"], y=df["ichi_senkou_a"], line=dict(width=0), name="é›²å±¤ä¸Šç·£"))
    fig.add_trace(go.Scatter(x=df["date"], y=df["ichi_senkou_b"], line=dict(width=0), name="é›²å±¤ä¸‹ç·£", fill="tonexty", fillcolor="rgba(100,100,255,0.2)"))
    fig.add_trace(go.Scatter(x=df["date"], y=df["ichi_tenkan"], line=dict(color="green", width=1), name="è½‰æ›ç·š"))
    fig.add_trace(go.Scatter(x=df["date"], y=df["ichi_kijun"], line=dict(color="red", width=1), name="åŸºæº–ç·š"))
    return fig

# å–®ä¸€è‚¡ç¥¨åˆ†æ
def analyze_single_stock(symbol, sector=""):
    try:
        df, fetch_time, source = fetch_price_data(symbol)
        if df is None or df.empty:
            logging.error(f"æ•¸æ“šç²å–å¤±æ•— for {symbol}")
            return None, None, None, None, None, None, None, None, None, None, None
        
        df, fib_levels, hs_patterns, dt_patterns = calculate_all_indicators(df, sector)
        signal, explanation, score, latest = enhanced_generate_signal(df, fib_levels, hs_patterns, dt_patterns, sector)
        
        # Prophet é æ¸¬
        forecast_trend = "N/A"
        current_price = None
        forecast = None
        df_prophet = None
        try:
            df_prophet = df[["date", "close", "volume"]].copy()
            df_prophet = df_prophet.rename(columns={"date": "ds", "close": "y"})
            df_prophet["ds"] = pd.to_datetime(df_prophet["ds"]).dt.tz_localize(None)
            
            nasdaq_df = fetch_nasdaq_data()
            if nasdaq_df is not None:
                df_prophet = df_prophet.merge(
                    nasdaq_df[["date", "nasdaq_close", "nasdaq_volume"]], 
                    left_on="ds", right_on="date", how="left"
                ).drop(columns=["date"])
                df_prophet["nasdaq_close"] = df_prophet["nasdaq_close"].ffill()
                df_prophet["nasdaq_volume"] = df_prophet["nasdaq_volume"].ffill()
            
            m = Prophet(daily_seasonality=True)
            if nasdaq_df is not None:
                m.add_regressor("nasdaq_close")
                m.add_regressor("nasdaq_volume")
                m.add_regressor("volume")
            
            m.fit(df_prophet)
            future = m.make_future_dataframe(periods=30)
            
            if nasdaq_df is not None:
                future = future.merge(
                    nasdaq_df[["date", "nasdaq_close", "nasdaq_volume"]], 
                    left_on="ds", right_on="date", how="left"
                ).drop(columns=["date"])
                future["nasdaq_close"] = future["nasdaq_close"].ffill()
                future["nasdaq_volume"] = future["nasdaq_volume"].ffill()
                future["volume"] = df_prophet["volume"].iloc[-1]
            
            forecast = m.predict(future)
            forecast_mean = forecast.tail(30)["yhat"].mean()
            current_price = df_prophet["y"].iloc[-1]
            forecast_trend = "ä¸Šæ¼²" if forecast_mean > current_price else "ä¸‹è·Œ"
        except Exception as e:
            logging.error(f"Prophet é æ¸¬å¤±æ•— for {symbol}: {e}")
        
        # ARIMA é æ¸¬
        arima_trend = "N/A"
        arima_forecast = None
        try:
            if df_prophet is not None:
                arima_model = auto_arima(df_prophet["y"], seasonal=True, m=7, suppress_warnings=True)
                arima_forecast = arima_model.predict(n_periods=30)
                arima_trend = "ä¸Šæ¼²" if arima_forecast.mean() > current_price else "ä¸‹è·Œ"
        except Exception as e:
            logging.error(f"ARIMA é æ¸¬å¤±æ•— for {symbol}: {e}")
        
        # XGBoostã€éš¨æ©Ÿæ£®æ—å’Œ LightGBM é æ¸¬
        model_results = []
        up_proba = None
        rf_proba = None
        lgbm_proba = None
        xgb_model = None
        try:
            df_xgb = df.copy()
            if len(df_xgb) < 100:
                up_proba = None
                rf_proba = None
                lgbm_proba = None
                logging.warning(f"æ•¸æ“šä¸è¶³ for ML models: {len(df_xgb)} rows")
            else:
                df_xgb["return"] = df_xgb["close"].pct_change()
                df_xgb["target"] = (df_xgb["return"].shift(-1) > 0).astype(int)
                df_xgb["ma5"] = df_xgb["close"].rolling(5).mean()
                df_xgb["ma20"] = df_xgb["close"].rolling(20).mean()
                df_xgb["rsi"] = ta.momentum.RSIIndicator(df_xgb["close"]).rsi()
                df_xgb["macd"] = ta.trend.MACD(df_xgb["close"]).macd_diff()
                df_xgb["adx"] = ta.trend.ADXIndicator(df_xgb["high"], df_xgb["low"], df_xgb["close"]).adx()
                df_xgb["vol"] = df_xgb["volume"]
                df_xgb["obv"] = df_xgb["obv"]
                df_xgb["52w_high"] = df_xgb["52w_high"]
                df_xgb["52w_low"] = df_xgb["52w_low"]
                
                nasdaq_df = fetch_nasdaq_data()
                if nasdaq_df is not None:
                    df_xgb = df_xgb.merge(nasdaq_df[["date", "nasdaq_close"]], on="date", how="left")
                    df_xgb["nasdaq_close"] = df_xgb["nasdaq_close"].ffill()
                    df_xgb["nasdaq_corr"] = df_xgb["close"].rolling(20, min_periods=10).corr(df_xgb["nasdaq_close"])
                
                df_xgb = df_xgb.dropna().copy()
                if df_xgb.empty:
                    up_proba = None
                    rf_proba = None
                    lgbm_proba = None
                    logging.warning(f"æ•¸æ“šæ¸…ç†å¾Œç‚ºç©º for {symbol}")
                else:
                    features = ["ma5", "ma20", "rsi", "macd", "adx", "vol", "obv", "52w_high", "52w_low"]
                    if nasdaq_df is not None and "nasdaq_corr" in df_xgb.columns:
                        features.append("nasdaq_corr")
                    
                    X = df_xgb[features]
                    y = df_xgb["target"]
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X)
                    
                    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)
                    
                    # XGBoost
                    xgb_model = GridSearchCV(XGBClassifier(eval_metric="logloss"), 
                                             param_grid={"max_depth": [3, 5, 7], "learning_rate": [0.01, 0.05, 0.1]}, 
                                             cv=5)
                    xgb_model.fit(X_train, y_train)
                    xgb_pred = xgb_model.predict(X_test)
                    xgb_acc = accuracy_score(y_test, xgb_pred)
                    xgb_proba = xgb_model.best_estimator_.predict_proba(X_scaled[-1:])[0][1]
                    model_results.append({"æ¨¡å‹": "XGBoost", "ä¸Šå‡æ©Ÿç‡ (%)": xgb_proba*100, "æ¸¬è©¦é›†æº–ç¢ºç‡ (%)": xgb_acc*100})
                    up_proba = xgb_proba
                    
                    # éš¨æ©Ÿæ£®æ—
                    rf_model = GridSearchCV(RandomForestClassifier(random_state=42), 
                                            param_grid={"n_estimators": [100, 200], "max_depth": [3, 5, 7]}, 
                                            cv=5)
                    rf_model.fit(X_train, y_train)
                    rf_pred = rf_model.predict(X_test)
                    rf_acc = accuracy_score(y_test, rf_pred)
                    rf_proba = rf_model.best_estimator_.predict_proba(X_scaled[-1:])[0][1]
                    model_results.append({"æ¨¡å‹": "Random Forest", "ä¸Šå‡æ©Ÿç‡ (%)": rf_proba*100, "æ¸¬è©¦é›†æº–ç¢ºç‡ (%)": rf_acc*100})
                    
                    # LightGBM
                    lgbm_model = GridSearchCV(LGBMClassifier(random_state=42), 
                                              param_grid={"max_depth": [3, 5, 7], "learning_rate": [0.01, 0.05, 0.1]}, 
                                              cv=5)
                    lgbm_model.fit(X_train, y_train)
                    lgbm_pred = lgbm_model.predict(X_test)
                    lgbm_acc = accuracy_score(y_test, lgbm_pred)
                    lgbm_proba = lgbm_model.best_estimator_.predict_proba(X_scaled[-1:])[0][1]
                    model_results.append({"æ¨¡å‹": "LightGBM", "ä¸Šå‡æ©Ÿç‡ (%)": lgbm_proba*100, "æ¸¬è©¦é›†æº–ç¢ºç‡ (%)": lgbm_acc*100})
        except Exception as e:
            logging.error(f"åˆ†é¡æ¨¡å‹é æ¸¬å¤±æ•— for {symbol}: {e}")
        
        return df, forecast_trend, (up_proba, rf_proba, lgbm_proba), (signal, explanation, score, latest), fetch_time, source, arima_forecast, model_results, arima_trend, forecast, df_prophet
    except Exception as e:
        logging.error(f"analyze_single_stock({symbol}) failed: {e}")
        return None, None, None, None, None, None, None, None, None, None, None

# ä¸»æ‡‰ç”¨
st.title("ğŸ“ˆ æ™ºèƒ½é¸è‚¡å¹³å° PRO (ç¾è‚¡ç‰ˆ)")

st.sidebar.header("ğŸ“‚ è‚¡ç¥¨åˆ†é¡")
category = st.sidebar.selectbox("é¸æ“‡åˆ†é¡ï¼š", list(stock_categories.keys()))
stock_list = stock_categories[category]

selected_symbol = None
for stock, name in stock_list:
    label = f"{stock} - {name}"
    if st.sidebar.button(label, key=f"btn_{stock}"):
        selected_symbol = stock

custom = st.sidebar.text_input("æˆ–è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ï¼š", "")
if custom:
    custom = custom.upper()
    if custom.strip() and custom.isalnum():  # é©—è­‰è¼¸å…¥
        selected_symbol = custom
    else:
        st.sidebar.error("è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼")

if selected_symbol:
    try:
        ticker = yf.Ticker(selected_symbol)
        sector = ticker.info.get("sector", "æœªçŸ¥")
    except Exception as e:
        logging.error(f"ç²å– {selected_symbol} sector å¤±æ•—: {e}")
        sector = "æœªçŸ¥"
        st.warning(f"ç„¡æ³•ç²å– {selected_symbol} çš„è¡Œæ¥­è³‡è¨Šï¼Œä½¿ç”¨é è¨­å€¼ 'æœªçŸ¥'")

    result = analyze_single_stock(selected_symbol, sector)
    
    if len(result) == 11:
        df, forecast_trend, probas, signal_data, fetch_time, source, arima_forecast, model_results, arima_trend, forecast, df_prophet = result
    else:
        df, forecast_trend, probas, signal_data, fetch_time, source, arima_forecast, model_results, arima_trend, forecast, df_prophet = None, None, None, None, None, None, None, None, None, None, None
    
    if df is not None and not df.empty and signal_data is not None:
        signal, explanation, score, latest = signal_data
        latest_price = df["close"].iloc[-1]
        up_proba, rf_proba, lgbm_proba = probas if probas else (None, None, None)
        
        # é¡¯ç¤ºè‚¡ç¥¨åç¨±ã€æœ€æ–°è‚¡åƒ¹å’Œæ•¸æ“šä¾†æº
        st.subheader(f"ğŸ” åˆ†æè‚¡ç¥¨ï¼š{selected_symbol} - {signal}")
        st.markdown(f"ğŸ’° **æœ€æ–°è‚¡åƒ¹**ï¼š${latest_price:.2f}")
        st.markdown(f"ğŸ“Œ **ç¶œåˆè©•åˆ†**ï¼š{score:.1f}/10")
        st.markdown(f"ğŸ“¡ **æ•¸æ“šä¾†æº**ï¼š{source}ï¼ˆå–å¾—æ™‚é–“ï¼š{fetch_time}ï¼‰")
        
        # æª¢æŸ¥è‚¡åƒ¹æ˜¯å¦åˆç†
        if selected_symbol == "TSLA" and abs(latest_price - 237.97) > 5:
            st.warning(f"âš ï¸ è‚¡åƒ¹å¯èƒ½æœªæ›´æ–°ï¼ŒTSLA æ‡‰æ¥è¿‘ $237.97ï¼ˆ2025-04-22 æ”¶ç›¤åƒ¹ï¼‰")

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("è¶¨å‹¢å¼·åº¦", f"{latest.adx:.1f}", "å¼·å‹¢" if latest.adx > 25 else "å¼±å‹¢", delta_color="inverse")
        with col2:
            st.metric("å¸‚å ´æ–¹å‘", "å¤šé ­" if latest["close"] > df["ma50"].iloc[-1] else "ç©ºé ­", f"{latest.close/df['ma50'].iloc[-1]-1:.2%}")
        with col3:
            st.metric("è¡Œæ¥­ç‰¹æ€§", sector, "é«˜æ³¢å‹•" if sector in ["Technology", "Consumer Cyclical"] else "ä¸€èˆ¬")
        
        with st.expander("ğŸ“‹ è©³ç´°è¨Šè™Ÿåˆ†æ", expanded=True):
            st.markdown("### ç•¶å‰å¸‚å ´ç‹€æ…‹")
            ma50_trend = "ä¸Šå‡" if latest["close"] > df["ma50"].iloc[-1] else "ä¸‹é™"
            st.write(f"- **è¶¨å‹¢æ–¹å‘**: {ma50_trend} (æ”¶ç›¤åƒ¹ {latest['close']:.2f} vs MA50 {df['ma50'].iloc[-1]:.2f})")
            st.write(f"- **VWAPä¿¡è™Ÿ**: {'å¤šé ­' if latest.vwap_signal else 'ç©ºé ­'} (åƒ¹æ ¼ {latest.close:.2f} vs VWAP {latest.vwap:.2f})")
            st.write(f"- **è¶¨å‹¢å¼·åº¦**: {'å¼·å‹' if latest.adx > 25 else 'æ™®é€š'} (ADXå€¼:{latest.adx:.1f})")
            
            st.markdown("### æŠ€è¡“æŒ‡æ¨™åˆ†æ")
            if not explanation:
                st.warning("âš ï¸ ç•¶å‰ç„¡æ˜é¡¯æŠ€è¡“ä¿¡è™Ÿ")
            else:
                for item in explanation:
                    if "è²·" in item or "æ¼²" in item:
                        st.success(f"âœ… {item}")
                    elif "è³£" in item or "è·Œ" in item:
                        st.error(f"âŒ {item}")
                    else:
                        st.info(f"â„¹ï¸ {item}")
        
        st.markdown("---")
        st.subheader("ğŸ“Š é€²éšæŠ€è¡“æŒ‡æ¨™åˆ†æ")
        fib_levels, hs_patterns, dt_patterns = calculate_all_indicators(df, sector)[1:4]
        st.markdown("### é»ƒé‡‘æ¯”ç‡å›èª¿ä½")
        fib_table = pd.DataFrame.from_dict(fib_levels, orient="index", columns=["åƒ¹ä½"])
        st.table(fib_table.style.format({"åƒ¹ä½": "{:.2f}"}))
        
        if hs_patterns or dt_patterns:
            st.markdown("### ğŸ”„ åœ–å½¢å½¢æ…‹")
            col1, col2 = st.columns(2)
            with col1:
                if hs_patterns:
                    st.write("#### é ­è‚©å½¢æ…‹")
                    st.dataframe(pd.DataFrame(hs_patterns, columns=["å½¢æ…‹", "æ—¥æœŸ"]).tail(3))
            with col2:
                if dt_patterns:
                    st.write("#### é›™é ‚/é›™åº•")
                    st.dataframe(pd.DataFrame(dt_patterns, columns=["å½¢æ…‹", "æ—¥æœŸ"]).tail(3))
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=df["date"], y=df["close"], name="æ”¶ç›¤åƒ¹", line=dict(color="#1f77b4")))
        fig.add_trace(go.Scatter(x=df["date"], y=df["ma20"], name="MA20", line=dict(dash="dot", color="#ff7f0e")))
        fig.add_trace(go.Scatter(x=df["date"], y=df["ma50"], name="MA50", line=dict(dash="dash", color="#2ca02c")))
        fig.add_trace(go.Scatter(x=df["date"], y=df["vwap"], name="VWAP", line=dict(color="#9467bd")))
        fig = plot_fibonacci_levels(fig, df, fib_levels)
        fig = plot_ichimoku(fig, df)
        fig.update_layout(title=f"{selected_symbol} æŠ€è¡“åˆ†æåœ–", xaxis_title="æ—¥æœŸ", yaxis_title="åƒ¹æ ¼", legend=dict(orientation="h"), hovermode="x unified")
        st.plotly_chart(fig, use_container_width=True)
        
        # Prophet å’Œ ARIMA é æ¸¬
        with st.expander("â³ AI æ¨¡çµ„ï¼šProphet & ARIMA é æ¸¬æœªä¾† 30 æ—¥", expanded=True):
            if forecast is None or df_prophet is None:
                st.error("âŒ Prophet é æ¸¬å¤±æ•—ï¼Œç„¡æ³•é¡¯ç¤ºé æ¸¬åœ–è¡¨")
            else:
                try:
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(x=df_prophet["ds"], y=df_prophet["y"], mode="lines", name="å¯¦éš›åƒ¹æ ¼", line=dict(color="#1f77b4")))
                    fig.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat"], mode="lines", name="Prophet é æ¸¬", line=dict(color="#2ca02c")))
                    fig.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat_upper"], mode="lines", line=dict(width=0), showlegend=False))
                    fig.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat_lower"], mode="lines", fill="tonexty", line=dict(width=0), fillcolor="rgba(31,119,180,0.2)", showlegend=False))
                    
                    # æ·»åŠ  ARIMA é æ¸¬
                    if arima_forecast is not None:
                        forecast_dates = pd.date_range(start=df["date"].iloc[-1] + dt.timedelta(days=1), periods=30)
                        fig.add_trace(go.Scatter(x=forecast_dates, y=arima_forecast, mode="lines", name="ARIMA é æ¸¬", line=dict(color="#ff7f0e")))
                    
                    fig.update_layout(title="Prophet & ARIMA é æ¸¬æœªä¾† 30 æ—¥æ”¶ç›¤åƒ¹", xaxis_title="æ—¥æœŸ", yaxis_title="åƒ¹æ ¼")
                    
                    forecast_next30 = forecast.tail(30).copy()
                    forecast_next30.loc[:, "é æ¸¬æ—¥"] = [f"T+{i+1}" for i in range(30)]
                    forecast_table = forecast_next30[["é æ¸¬æ—¥", "ds", "yhat", "yhat_lower", "yhat_upper"]]
                    forecast_table.columns = ["é æ¸¬æ—¥", "æ—¥æœŸ", "Prophet é æ¸¬æ”¶ç›¤åƒ¹", "æœ€ä½ä¼°åƒ¹", "æœ€é«˜ä¼°åƒ¹"]
                    if arima_forecast is not None:
                        forecast_table.loc[:, "ARIMA é æ¸¬æ”¶ç›¤åƒ¹"] = arima_forecast
                    
                    st.subheader("ğŸ“‹ Prophet & ARIMA é æ¸¬æœªä¾† 30 æ—¥åƒ¹æ ¼è©³æƒ…")
                    st.dataframe(
                        forecast_table.style.format({
                            "Prophet é æ¸¬æ”¶ç›¤åƒ¹": "{:.2f}", 
                            "æœ€ä½ä¼°åƒ¹": "{:.2f}", 
                            "æœ€é«˜ä¼°åƒ¹": "{:.2f}",
                            "ARIMA é æ¸¬æ”¶ç›¤åƒ¹": "{:.2f}" if arima_forecast is not None else None
                        })
                    )
                    st.markdown("ğŸ“ˆ **é æ¸¬è§£è®€**: è—è‰²ç·šç‚ºå¯¦éš›åƒ¹æ ¼ï¼Œç¶ è‰²ç·šç‚º Prophet é æ¸¬ï¼Œæ©™è‰²ç·šç‚º ARIMA é æ¸¬ï¼Œæ·ºè—è‰²ç‚º Prophet çš„ 80% ç½®ä¿¡å€é–“")
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"âŒ ç¹ªè£½ Prophet & ARIMA é æ¸¬åœ–è¡¨å¤±æ•—ï¼š{e}")
        
        # XGBoostã€éš¨æ©Ÿæ£®æ—å’Œ LightGBM é æ¸¬
        with st.expander("ğŸš€ AI æ¨¡çµ„ï¼šXGBoost, Random Forest, LightGBM å‡è·Œé æ¸¬", expanded=True):
            if up_proba is None and rf_proba is None and lgbm_proba is None:
                st.warning("âš ï¸ æ•¸æ“šä¸è¶³ï¼ˆå°‘æ–¼100å¤©ï¼‰æˆ–è™•ç†å¤±æ•—ï¼Œç„¡æ³•é€²è¡Œæ¼²è·Œé æ¸¬")
            else:
                st.write(f"ğŸ“ˆ **XGBoost é æ¸¬ä¸‹ä¸€æ—¥ä¸Šå‡æ©Ÿç‡**ï¼š{up_proba*100:.2f}%")
                st.write(f"ğŸ“ˆ **Random Forest é æ¸¬ä¸‹ä¸€æ—¥ä¸Šå‡æ©Ÿç‡**ï¼š{rf_proba*100:.2f}%")
                st.write(f"ğŸ“ˆ **LightGBM é æ¸¬ä¸‹ä¸€æ—¥ä¸Šå‡æ©Ÿç‡**ï¼š{lgbm_proba*100:.2f}%")
                
                # é¡¯ç¤ºæ¨¡å‹æ¯”è¼ƒè¡¨æ ¼
                st.write("### æ¨¡å‹æ¯”è¼ƒ")
                comparison = pd.DataFrame(model_results)
                st.dataframe(comparison.style.format({"ä¸Šå‡æ©Ÿç‡ (%)": "{:.2f}", "æ¸¬è©¦é›†æº–ç¢ºç‡ (%)": "{:.2f}"}))

                if st.checkbox("é¡¯ç¤º XGBoost ç‰¹å¾µé‡è¦æ€§åœ–è¡¨") and xgb_model is not None:
                    st.markdown("### ğŸ¯ XGBoost ç‰¹å¾µé‡è¦æ€§")
                    explainer = shap.Explainer(xgb_model.best_estimator_)
                    shap_values = explainer(X)
                    shap.summary_plot(shap_values, X, plot_type="bar", show=False)
                    st.pyplot(plt.gcf())
        
        # ç¶œåˆç¸½çµ
        st.markdown("---")
        st.markdown("### ç¶œåˆç¸½çµï¼šè²·å®šå””è²·")
        if score >= 5 or (up_proba is not None and up_proba > 0.6 and forecast_trend == "ä¸Šæ¼²"):
            reasons = ["æŠ€è¡“æŒ‡æ¨™å¼·å‹¢"]
            if any("é ­è‚©åº•" in item or "é›™åº•" in item for item in explanation):
                reasons.append("åœ–å½¢å½¢æ…‹æ”¯æŒåè½‰")
            if rf_proba is not None and rf_proba > 0.6:
                reasons.append("éš¨æ©Ÿæ£®æ—é æ¸¬çœ‹æ¼²")
            if lgbm_proba is not None and lgbm_proba > 0.6:
                reasons.append("LightGBM é æ¸¬çœ‹æ¼²")
            if arima_trend is not None and arima_trend == "ä¸Šæ¼²":
                reasons.append("ARIMA é æ¸¬çœ‹æ¼²")
            st.success(f"âœ… **å»ºè­°ï¼šè²·** - {', '.join(reasons)}")
        else:
            reason = []
            if score < 3:
                reason.append(f"æŠ€è¡“æŒ‡æ¨™åå¼±ï¼ˆè©•åˆ† {score:.1f}ï¼‰")
            if up_proba is None or up_proba < 0.6:
                reason.append(f"XGBoost çŸ­æœŸä¸Šå‡æ©Ÿç‡ä½ï¼ˆ{up_proba*100:.2f}%ï¼‰")
            if rf_proba is None or rf_proba < 0.6:
                reason.append(f"éš¨æ©Ÿæ£®æ—çŸ­æœŸä¸Šå‡æ©Ÿç‡ä½ï¼ˆ{rf_proba*100:.2f}%ï¼‰")
            if lgbm_proba is None or lgbm_proba < 0.6:
                reason.append(f"LightGBM çŸ­æœŸä¸Šå‡æ©Ÿç‡ä½ï¼ˆ{lgbm_proba*100:.2f}%ï¼‰")
            if forecast_trend != "ä¸Šæ¼²":
                reason.append("Prophet é æ¸¬ 30 å¤©è¶¨å‹¢ä¸æ˜")
            if arima_trend is None or arima_trend != "ä¸Šæ¼²":
                reason.append("ARIMA é æ¸¬ 30 å¤©è¶¨å‹¢ä¸æ˜")
            st.error(f"âŒ **å»ºè­°ï¼šå””è²·** - {', '.join(reason)}")
    else:
        st.error(f"âŒ ç„¡æ³•ç²å– {selected_symbol} çš„æ•¸æ“šï¼Œè«‹æª¢æŸ¥ä»£ç¢¼æˆ–ç¶²çµ¡é€£ç·šã€‚")
else:
    st.info("ğŸ’¡ è«‹é¸æ“‡è‚¡ç¥¨æˆ–è¼¸å…¥ä»£ç¢¼é–‹å§‹åˆ†æã€‚")
